{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src/')\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "from jcamp import JCAMP_reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from rdkit import Chem\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IR spectrum reader from Jcamp file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "THRESHOLD_IR = 0.93\n",
    "THRESHOLD_NMR = 0.02\n",
    "curve_begin_idx = 600\n",
    "curve_correction_factor = 0.5\n",
    "\n",
    "class SpectraCarrier():\n",
    "    def __init__(self, path, params=False):\n",
    "        self.data_dic = JCAMP_reader(path)\n",
    "        #print(self.data_dic)\n",
    "        self.x = self.data_dic['x']\n",
    "        self.y = self.data_dic['y']\n",
    "        self.xfactor = self.data_dic['xfactor']\n",
    "        self.yfactor = self.data_dic['yfactor']\n",
    "        #self.molform = self.data_dic['molform']\n",
    "        self.deltax = self.data_dic['deltax']\n",
    "        self.firstx = self.data_dic['firstx']\n",
    "        self.lastx = self.data_dic['lastx']\n",
    "        self.firsty = self.data_dic['firsty']\n",
    "        #self.maxx = self.data_dic['maxx']\n",
    "        #self.minx = self.data_dic['minx']\n",
    "        self.maxy = self.data_dic['maxy']\n",
    "        self.miny = self.data_dic['miny']\n",
    "    \n",
    "\n",
    "def order(x_i, y_i):\n",
    "    x_o = x_i\n",
    "    y_o = y_i\n",
    "\n",
    "    first_x = x_i[0]\n",
    "    last_x = x_i[-1]\n",
    "    if first_x > last_x:\n",
    "        x_o = x_o[::-1]\n",
    "        y_o = y_o[::-1]\n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def concat_boundary(x_i, y_i):\n",
    "    x_head = np.array([0.0])\n",
    "    x_tail = np.array([4000.0])\n",
    "    x_o = np.concatenate([x_head, x_i, x_tail])\n",
    "\n",
    "    y_head = np.array([y_i[0]])\n",
    "    y_tail = np.array([y_i[-1]])\n",
    "    y_o = np.concatenate([y_head, y_i, y_tail])\n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def sampling(x_i, y_i):\n",
    "    f = interpolate.interp1d(x_i, y_i)\n",
    "    x_o = np.linspace(0, 3999, 4000, endpoint=True)\n",
    "    y_o = f(x_o)\n",
    "    return x_o[curve_begin_idx:], y_o[curve_begin_idx:]\n",
    "\n",
    "\n",
    "def normalize(x_i, y_i):\n",
    "    max_y = np.max(y_i)\n",
    "    min_y = np.min(y_i)\n",
    "    height = max_y - min_y\n",
    "\n",
    "    x_o = x_i\n",
    "    y_o = (y_i - min_y) / height\n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def to_absorption(x_i, y_i):\n",
    "    x_o = x_i\n",
    "    y_o = -np.log10(y_i)\n",
    "    \n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def chop(x_i, y_i):\n",
    "    x_o = x_i[0:]\n",
    "    y_o = y_i[0:]\n",
    "    \n",
    "    return x_o, y_o\n",
    "\n",
    "\n",
    "def read_spectrum(path, to_absorption):\n",
    "    sc = SpectraCarrier(path)\n",
    "\n",
    "    # original\n",
    "    x_orig, y_orig = order(sc.x, sc.y)\n",
    "\n",
    "    # concatenate\n",
    "    x_basis, y_basis = concat_boundary(x_orig, y_orig)\n",
    "\n",
    "    #interpolate\n",
    "    x_new, y_new = sampling(x_basis, y_basis)\n",
    "    y_new = y_new ** curve_correction_factor\n",
    "\n",
    "    #absorption\n",
    "    if to_absorption :\n",
    "        x_new_norm_abs, y_new_norm_abs = to_absorption(x_new, y_new)\n",
    "    else :\n",
    "        x_new_norm_abs, y_new_norm_abs = x_new, y_new\n",
    "\n",
    "    #normalized\n",
    "    x_new_norm, y_new_norm = normalize(x_new_norm_abs, y_new_norm_abs)\n",
    "\n",
    "    # chomp\n",
    "    x_nnac, y_nnac = chop(x_new_norm, y_new_norm)\n",
    "    \n",
    "    return x_nnac, y_nnac\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to read Chemotion dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_folder = 'data/exp/'\n",
    "filepath = '{}meta_data.json'.format(data_folder)\n",
    "\n",
    "columns = ['id', 'cano_smi', 'smiles', 'spectrum']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "errors = []\n",
    "cou = 0\n",
    "with open(filepath, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        smiles = data[i]['cano_smiles']\n",
    "        id = data[i]['identifier']\n",
    "        filepath = data_folder+id\n",
    "        try:\n",
    "            _, spec = read_spectrum(filepath, False)\n",
    "        except (KeyError, Exception):\n",
    "            errors.append(id)\n",
    "            \n",
    "        molfromsmi = Chem.MolFromSmiles(data[i]['cano_smiles'])\n",
    "        if molfromsmi is None:\n",
    "            errors.append(id)\n",
    "            continue\n",
    "        cano = Chem.MolToSmiles(Chem.MolFromSmiles(data[i]['cano_smiles']))\n",
    "        row = [id, cano, smiles, spec] \n",
    "        df2 = pd.DataFrame(np.array(row).reshape(1,-1), columns= columns, index = [i])\n",
    "\n",
    "        df = df.append(df2, ignore_index=True)\n",
    "df.to_pickle('./chemIR_raw.pk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to read NIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_data = 'data/nist/IR/cas-index.txt'\n",
    "folderpath = 'data/nist/IR/Individual_Files/NIST/DX/'\n",
    "casids = []\n",
    "\n",
    "with open(nist_data, 'r') as f :\n",
    "    d = f.readlines()\n",
    "    for j in d:\n",
    "        casids.append(j[0:15])\n",
    "\n",
    "mol = np.load('data/nist/IR/cas-smiles.npy')\n",
    "\n",
    "columns = ['id', 'cano_smi', 'smiles', 'spectrum']\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for idx, i in enumerate(casids):\n",
    "    filepath = folderpath+i.strip()+'.DX'\n",
    "    errors = []\n",
    "    try:\n",
    "         _, spec = read_spectrum(filepath, False)\n",
    "    except (KeyError, Exception) as e:\n",
    "            errors.append(i)\n",
    "            continue\n",
    "    \n",
    "    molfromsmi = Chem.MolFromSmiles(mol[idx])\n",
    "    if molfromsmi is None:\n",
    "        errors.append(id)\n",
    "        continue\n",
    "    cano = Chem.MolToSmiles(molfromsmi)\n",
    "\n",
    "    # func = ifg.identify_functional_groups(molfromsmi)\n",
    "\n",
    "    # rd_func = np.unique([i.type for i in func])\n",
    "\n",
    "    # onehot = seq_onehot(rd_func, fg_lis)\n",
    "    row = [idx, cano, mol[idx], spec] \n",
    "    # row.extend(onehot)\n",
    "    df2 = pd.DataFrame(np.array(row).reshape(1,-1), columns= columns, index = [i])\n",
    "\n",
    "    df = df.append(df2, ignore_index=True)\n",
    "\n",
    "df.to_pickle('./nist.pk')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot raw Chemotion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inhouse = np.load('./chemIR_raw.pk', allow_pickle= True)\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(df_inhouse.shape[0]):\n",
    "    plt.plot(df_inhouse.loc[i].spectrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z score based filtering for Chemotion dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([x for x in df_inhouse.spectrum]) \n",
    "arr = arr[:,3200:]\n",
    "print(df_inhouse.shape)\n",
    "xdf = df_inhouse[(np.abs(stats.zscore(arr)) < 2).all(axis=1)]\n",
    "arr = np.array([x for x in xdf.spectrum]) \n",
    "arr = arr[:,1800:1900]\n",
    "xdf = xdf[(np.abs(stats.zscore(arr)) < 2).all(axis=1)]\n",
    "print(xdf.shape)\n",
    "xdf = xdf.drop_duplicates(subset=['cano_smi'], keep='last')\n",
    "xdf = xdf.reset_index(drop=True)\n",
    "print(xdf.shape)\n",
    "xdf.to_pickle('./chemIR_filtered.pk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot filtered Chemotion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(xdf.shape[0]):\n",
    "    plt.plot(xdf.loc[i].spectrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to label dataset with ground truth functional groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_grp_smarts = {'alkane':'[CX4;H0,H1,H2,H4]',\n",
    "                   'methyl':'[CH3]',\n",
    "                   'alkene':'[CX3]=[CX3]',\n",
    "                   'alkyne':'[CX2]#C',\n",
    "                   'alcohols':'[#6][OX2H]',\n",
    "                   'amines':'[NX3;H2,H1;!$(NC=O)]',\n",
    "                   'nitriles':'[NX1]#[CX2]', \n",
    "                   'aromatics':'[$([cX3](:*):*),$([cX2+](:*):*)]',\n",
    "                   'alkyl halides':'[#6][F,Cl,Br,I]', \n",
    "                   'esters':'[#6][CX3](=O)[OX2H0][#6]',\n",
    "                   'ketones':'[#6][CX3](=O)[#6]',\n",
    "                   'aldehydes':'[CX3H1](=O)[#6]', \n",
    "                   'carboxylic acids':'[CX3](=O)[OX2H1]',\n",
    "                #    'ether': '[OD2]([#6])[#6]',\n",
    "                   'ether': '[OD2]([#6;!$(C=O)])([#6;!$(C=O)])',\n",
    "                   'acyl halides':'[CX3](=[OX1])[F,Cl,Br,I]',\n",
    "                   'amides':'[NX3][CX3](=[OX1])[#6]',\n",
    "                   'nitro':'[$([NX3](=O)=O),$([NX3+](=O)[O-])][!#8]'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def identify_functional_groups(smiles):\n",
    "    '''Identify the presence of functional groups present in molecule \n",
    "       denoted by smiles\n",
    "    Args:\n",
    "        root: (string) path to spectra data\n",
    "        files: (list) jdx files present in root\n",
    "        save_path: (string) path to store csv file\n",
    "        bins: (np.array) used for standardizing\n",
    "        is_mass: (bool) whether data being parsed is Mass or IR\n",
    "    Returns:\n",
    "        mol_func_groups: (list) contains binary values of functional groups presence\n",
    "                          None if smiles to molecule conversion returns warning or error\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        #Convert inchi to molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)#, treatWarningAsError=True)\n",
    "\n",
    "        mol_func_grps = []\n",
    "\n",
    "        #populate the list with binary values\n",
    "        for _, func_struct in func_grp_structs.items():\n",
    "            struct_matches = mol.GetSubstructMatches(func_struct)\n",
    "            contains_func_grp = int(len(struct_matches)>0)\n",
    "            mol_func_grps.append(contains_func_grp)\n",
    "        return mol_func_grps\n",
    "    except:\n",
    "\n",
    "        return None\n",
    "\n",
    "def save_target_to_csv(smiles_df, save_path, func_grp_structs):\n",
    "    '''Save the target dataframe as csv to path\n",
    "    Args:\n",
    "        smiles_df: (pd.DataFrame) contains CAS and Inchi of molecules\n",
    "        save_path: (string) path to store csv file\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    column_names = list(func_grp_structs.keys())\n",
    "    column_names = ['id', 'cano_smi', 'smiles', 'spectrum'] + column_names\n",
    "    target_df = pd.DataFrame(index = smiles_df.index, columns = column_names)\n",
    "\n",
    "    #Iterate the rows, don't use df.apply since a list is being returned.\n",
    "    for ind, (_, row) in enumerate(smiles_df.iterrows()):   \n",
    "\n",
    "        labels = identify_functional_groups(row['cano_smi'])\n",
    "        new_row = [ind, row['cano_smi'], row['smiles'], row['spectrum']] +labels\n",
    "        target_df.iloc[ind, :] = new_row\n",
    "\n",
    "    target_df.dropna(inplace = True)\n",
    "    target_df.to_pickle(save_path)\n",
    "\n",
    "smiles_df = np.load('./nist_epa.pk', allow_pickle=True)\n",
    "\n",
    "func_grp_structs = {func_name : Chem.MolFromSmarts(func_smarts) for func_name, func_smarts in func_grp_smarts.items()}\n",
    "save_target_to_csv(smiles_df, './nist_dataset.pk', func_grp_structs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to create Chemotion dataset subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nist = np.load('./nist_dataset.pk', allow_pickle=True)\n",
    "inh = np.load('./chemIR_dataset.pk', allow_pickle=True)\n",
    "\n",
    "nit_alk = inh[(inh['nitriles'] == 1) | (inh['alkyl halides'] == 1)]\n",
    "nit_alk.to_pickle('./chemo_sub.pk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to concatenate different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = np.load('./nist_dataset.pk', allow_pickle=True)\n",
    "df2 = np.load('./chemo_sub.pk', allow_pickle=True)\n",
    "\n",
    "pd.concat([df1,df2]).to_pickle('./mix_sub.pk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
